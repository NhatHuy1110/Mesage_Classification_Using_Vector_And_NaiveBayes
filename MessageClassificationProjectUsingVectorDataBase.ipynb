{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0ZNlbfduQLr"
      },
      "source": [
        "## Faiss(Facebook AI Similarity Search): Thư viện cho việc tìm kiếm tương đồng trên vector một cách hiệu quả.\n",
        "## Pandas, Numpy: Dành cho việc xử lý và thao tác dữ liệu.\n",
        "## Torch, transformers: Để tải và sử dụng mô hình embedding ngôn ngữ từ Hugging Face.\n",
        "## Sklearn: Dùng để chia dữ liệu và mã hóa nhãn.\n",
        "## Tqdm: Để hiển thị thanh tiến trình progress bar khi xử lý các tác vụ tốn thời gian."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4OqAl1Ho5Pb",
        "outputId": "d2e453ab-7ea8-410d-e87c-fe41f884a6ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq faiss-cpu\n",
        "!pip install -qq transformers\n",
        "!pip install -qq pandas\n",
        "!pip install -qq numpy\n",
        "!pip install -qq scikit-learn\n",
        "!pip install -qq tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhhcrA3SwD93",
        "outputId": "fada719d-c6de-4841-f12f-1571b2d006d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1N7rk-kfnDFIGMeX0ROVTjKh71gcgx-7R\n",
            "To: /content/2cls_spam_text_cls.csv\n",
            "100% 486k/486k [00:00<00:00, 6.65MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1N7rk-kfnDFIGMeX0ROVTjKh71gcgx-7R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2-xOBvWswL1f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import faiss\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8RzG0vjwxV_"
      },
      "source": [
        "## Đọc và Chuẩn bị dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "E_kbgNTbwwJW",
        "outputId": "448a05fa-0e54-4693-cc19-ac5876f307c1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5157,\n        \"samples\": [\n          \"Also sir, i sent you an email about how to log into the usc payment portal. I.ll send you another message that should explain how things are back home. Have a great weekend.\",\n          \"Are you free now?can i call now?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-dc7b9a59-e869-4d29-8dc0-a012e9d48e9b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc7b9a59-e869-4d29-8dc0-a012e9d48e9b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc7b9a59-e869-4d29-8dc0-a012e9d48e9b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc7b9a59-e869-4d29-8dc0-a012e9d48e9b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1e239f65-ae7a-48da-8eca-9235ffee7163\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e239f65-ae7a-48da-8eca-9235ffee7163')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1e239f65-ae7a-48da-8eca-9235ffee7163 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_453ba777-36b1-4fba-a0dc-4ec943d3e82f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_453ba777-36b1-4fba-a0dc-4ec943d3e82f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     Category                                            Message\n",
              "0         ham  Go until jurong point, crazy.. Available only ...\n",
              "1         ham                      Ok lar... Joking wif u oni...\n",
              "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3         ham  U dun say so early hor... U c already then say...\n",
              "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...       ...                                                ...\n",
              "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568      ham               Will ü b going to esplanade fr home?\n",
              "5569      ham  Pity, * was in mood for that. So...any other s...\n",
              "5570      ham  The guy did some bitching but I acted like i'd...\n",
              "5571      ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DATASET_PATH = \"/content/2cls_spam_text_cls.csv\"\n",
        "df = pd.read_csv(DATASET_PATH)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jGDc27GOxD2Y"
      },
      "outputs": [],
      "source": [
        "messages = df['Message'].values.tolist()\n",
        "labels = df['Category'].values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u5G8vtrxRYq"
      },
      "source": [
        "## Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRO7aIRKxNQi",
        "outputId": "77fcfb86-ac59-4186-baf2-e63bebaa6df6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--intfloat--multilingual-e5-base/snapshots/835193815a3936a24a0ee7dc9e3d48c1fbb19c55/sentencepiece.bpe.model\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--intfloat--multilingual-e5-base/snapshots/835193815a3936a24a0ee7dc9e3d48c1fbb19c55/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--intfloat--multilingual-e5-base/snapshots/835193815a3936a24a0ee7dc9e3d48c1fbb19c55/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--intfloat--multilingual-e5-base/snapshots/835193815a3936a24a0ee7dc9e3d48c1fbb19c55/tokenizer_config.json\n",
            "loading file chat_template.jinja from cache at None\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--intfloat--multilingual-e5-base/snapshots/835193815a3936a24a0ee7dc9e3d48c1fbb19c55/config.json\n",
            "Model config XLMRobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.54.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--intfloat--multilingual-e5-base/snapshots/835193815a3936a24a0ee7dc9e3d48c1fbb19c55/model.safetensors\n",
            "All model checkpoint weights were used when initializing XLMRobertaModel.\n",
            "\n",
            "All the weights of XLMRobertaModel were initialized from the model checkpoint at intfloat/multilingual-e5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = \"intfloat/multilingual-e5-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModel.from_pretrained(MODEL_NAME)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Hàm này để trích xuất embedding từ output của model\n",
        "def average_pool(last_hidden_states, attention_mask):\n",
        "  last_hidden = last_hidden_states.masked_fill(\n",
        "      ~attention_mask[..., None].bool(), 0.0\n",
        "  )\n",
        "  return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "def encode_text(batch_texts, model, tokenizer, device):\n",
        "    batch_dict = tokenizer(\n",
        "        batch_texts,\n",
        "        max_length=512,\n",
        "        padding=True,              # chèn [PAD] để độ dài các câu bằng nhau\n",
        "        truncation=True,           # cắt khi len > max_len\n",
        "        return_tensors='pt'        # trả về tensor Pytorch\n",
        "    )\n",
        "\n",
        "    # Chuyển data qua GPU để chạy\n",
        "    batch_dict = {k: v.to(device) for k, v in batch_dict.items()}\n",
        "\n",
        "    # Generate embeddings\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch_dict)\n",
        "        batch_embeddings = average_pool(\n",
        "            outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "        # Normalize embeddings\n",
        "        batch_embeddings = F.normalize(batch_embeddings, p=2, dim=1)\n",
        "\n",
        "    return batch_embeddings.cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWtM-epmyxVX"
      },
      "source": [
        "## Vector hóa dữ liệu và tạo metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyDejHEVy2NC"
      },
      "outputs": [],
      "source": [
        "def get_embeddings(texts, model, tokenizer, device, batch_size=32):\n",
        "    \"\"\"Generate embeddings for a list of texts\"\"\"\n",
        "    embeddings = []\n",
        "\n",
        "    for i in tqdm(range(0,len(texts),batch_size),desc=\"Generating embeddings\"):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "\n",
        "        # Add passage prefix for better retrieval performance\n",
        "        # batch_texts_with_prefix = [f\"passage: {text}\" for text in batch_texts]\n",
        "\n",
        "        batch_embeddings = encode_text(batch_texts, model, tokenizer, device)\n",
        "        embeddings.append(batch_embeddings)\n",
        "\n",
        "    return np.vstack(embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECYMhIeL4D5i",
        "outputId": "0677315e-1c9f-4091-c55d-5c9727aaa268"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: ['ham' 'spam']\n",
            "Generating embeddings for 5572 messages...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:   0%|          | 0/175 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "Generating embeddings: 100%|██████████| 175/175 [00:20<00:00,  8.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings shape: (5572, 768)\n",
            "Created metadata for 5572 documents\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Prepare labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(labels)\n",
        "print(f'Classes: {le.classes_}')\n",
        "\n",
        "# Generate embeddings cho tất cả messages\n",
        "print(f\"Generating embeddings for {len(messages)} messages...\")\n",
        "X_embeddings = get_embeddings(messages, model, tokenizer, device)\n",
        "print(f\"Embeddings shape: {X_embeddings.shape}\")\n",
        "\n",
        "# Tạo metadata cho mỗi document\n",
        "metadata = []\n",
        "for i, (message, label) in enumerate(zip(messages, labels)):\n",
        "    metadata.append({\n",
        "        'index': i,\n",
        "        'message': message,\n",
        "        'label': label,\n",
        "        'label_encoded': y[i]\n",
        "    })\n",
        "\n",
        "print(f\"Created metadata for {len(metadata)} documents\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8trbiJ004d-"
      },
      "source": [
        "## Xây dựng Cơ sở dữ liệu Vector và Chia dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76MDRqHP09RW",
        "outputId": "d866ed1b-26ba-4a04-92b4-12e72dab98f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 5014\n",
            "Test size: 558\n",
            "Train label distribution: [4342  672]\n",
            "Test label distribution: [483  75]\n"
          ]
        }
      ],
      "source": [
        "# Chia data thành train và test (90% train, 10% test)\n",
        "TEST_SIZE = 0.1\n",
        "SEED = 42\n",
        "\n",
        "train_indices, test_indices = train_test_split(\n",
        "    range(len(messages)),\n",
        "    test_size=TEST_SIZE,\n",
        "    stratify=y,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "# Chia embeddings và metadata\n",
        "X_train_emb = X_embeddings[train_indices]\n",
        "X_test_emb = X_embeddings[test_indices]\n",
        "y_train = y[train_indices]\n",
        "y_test = y[test_indices]\n",
        "\n",
        "train_metadata = [metadata[i] for i in train_indices]\n",
        "test_metadata = [metadata[i] for i in test_indices]\n",
        "\n",
        "print(f\"Train size: {len(X_train_emb)}\")\n",
        "print(f\"Test size: {len(X_test_emb)}\")\n",
        "print(f\"Train label distribution: {np.bincount(y_train)}\")\n",
        "print(f\"Test label distribution: {np.bincount(y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMTKfXKk4PFY",
        "outputId": "0b54f1c3-01ee-4a4c-dc54-1d44d9306061"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index created with 5014 vectors\n"
          ]
        }
      ],
      "source": [
        "# Tạo FAISS index\n",
        "embedding_dim = X_train_emb.shape[1]\n",
        "index = faiss.IndexFlatIP(embedding_dim)  # Inner product cho cosine similarity\n",
        "index.add(X_train_emb.astype('float32'))\n",
        "\n",
        "print(f\"FAISS index created with {index.ntotal} vectors\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyfvLvo-11L_"
      },
      "source": [
        "## Xây dựng logic phân loại và đánh giá"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e-AF2zw15mI"
      },
      "outputs": [],
      "source": [
        "def classify_with_knn(query_text, model, tokenizer, device, index, train_metadata, k=1):\n",
        "    \"\"\"Classify text using k-nearest neighbors with embeddings\"\"\"\n",
        "\n",
        "    # Lấy query embedding\n",
        "    query_with_prefix = f\"query: {query_text}\"\n",
        "    query_embedding = encode_text([query_with_prefix], model, tokenizer, device)\n",
        "\n",
        "    # Tìm trong FAISS index\n",
        "    scores, indices = index.search(query_embedding, k)\n",
        "\n",
        "    # Lấy predictions từ top-k neighbors\n",
        "    predictions = []\n",
        "    neighbor_info = []\n",
        "\n",
        "    for i in range(k):\n",
        "        neighbor_idx = indices[0][i]\n",
        "        neighbor_score = scores[0][i]\n",
        "        neighbor_label = train_metadata[neighbor_idx]['label']\n",
        "        neighbor_message = train_metadata[neighbor_idx]['message']\n",
        "\n",
        "        predictions.append(neighbor_label)\n",
        "        neighbor_info.append({\n",
        "            'score': float(neighbor_score),\n",
        "            'label': neighbor_label,\n",
        "            'message': neighbor_message[:100] + \"...\" if len(neighbor_message) > 100 else neighbor_message\n",
        "        })\n",
        "\n",
        "    # Majority vote for final prediction\n",
        "    unique_labels, counts = np.unique(predictions, return_counts=True)\n",
        "    final_prediction = unique_labels[np.argmax(counts)]\n",
        "\n",
        "    return final_prediction, neighbor_info\n",
        "\n",
        "def evaluate_knn_accuracy(test_embeddings, test_labels, test_metadata, index, train_metadata, k_values=[1, 3, 5]):\n",
        "    \"\"\"Evaluate accuracy for different k values using precomputed embeddings\"\"\"\n",
        "    results = {}\n",
        "    all_errors = {}\n",
        "\n",
        "    for k in k_values:\n",
        "        correct = 0\n",
        "        total = len(test_embeddings)\n",
        "        errors = []\n",
        "\n",
        "        for i in tqdm(range(total), desc=f\"Evaluating k={k}\"):\n",
        "            query_embedding = test_embeddings[i:i+1].astype('float32')\n",
        "            true_label = test_metadata[i]['label']\n",
        "            true_message = test_metadata[i]['message']\n",
        "\n",
        "            # Tìm trong FAISS index\n",
        "            scores, indices = index.search(query_embedding, k)\n",
        "\n",
        "            # Lấy predictions từ top-k neighbors\n",
        "            predictions = []\n",
        "            neighbor_details = []\n",
        "            for j in range(k):\n",
        "                neighbor_idx = indices[0][j]\n",
        "                neighbor_label = train_metadata[neighbor_idx]['label']\n",
        "                neighbor_message = train_metadata[neighbor_idx]['message']\n",
        "                neighbor_score = float(scores[0][j])\n",
        "\n",
        "                predictions.append(neighbor_label)\n",
        "                neighbor_details.append({\n",
        "                    'label': neighbor_label,\n",
        "                    'message': neighbor_message,\n",
        "                    'score': neighbor_score\n",
        "                })\n",
        "\n",
        "            # Majority vote\n",
        "            unique_labels, counts = np.unique(predictions, return_counts=True)\n",
        "            predicted_label = unique_labels[np.argmax(counts)]\n",
        "\n",
        "            if predicted_label == true_label:\n",
        "                correct += 1\n",
        "            else:\n",
        "                # Thu thập error information\n",
        "                error_info = {\n",
        "                    'index': i,\n",
        "                    'original_index': test_metadata[i]['index'],\n",
        "                    'message': true_message,\n",
        "                    'true_label': true_label,\n",
        "                    'predicted_label': predicted_label,\n",
        "                    'neighbors': neighbor_details,\n",
        "                    'label_distribution': {label: int(count) for label, count in zip(unique_labels, counts)}\n",
        "                }\n",
        "                errors.append(error_info)\n",
        "\n",
        "        accuracy = correct / total\n",
        "        error_count = total - correct\n",
        "\n",
        "        results[k] = accuracy\n",
        "        all_errors[k] = errors\n",
        "\n",
        "        print(f\"Accuracy with k={k}: {accuracy:.4f}\")\n",
        "        print(f\"Number of errors with k={k}: {error_count}/{total} ({(error_count/total)*100:.2f}%)\")\n",
        "\n",
        "    return results, all_errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k06puqxe2CiR"
      },
      "source": [
        "## Đánh giá mô hình trên tập test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCyZohLV2G2P",
        "outputId": "0a9d4ee1-aa58-4713-9500-154985516e31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating accuracy on test set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating k=1: 100%|██████████| 558/558 [00:01<00:00, 343.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy with k=1: 0.9928\n",
            "Number of errors with k=1: 4/558 (0.72%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating k=3: 100%|██████████| 558/558 [00:00<00:00, 688.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy with k=3: 0.9910\n",
            "Number of errors with k=3: 5/558 (0.90%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating k=5: 100%|██████████| 558/558 [00:00<00:00, 1280.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy with k=5: 0.9892\n",
            "Number of errors with k=5: 6/558 (1.08%)\n",
            "\n",
            "==================================================\n",
            "ACCURACY RESULTS\n",
            "==================================================\n",
            "Top-1 accuracy: 0.9928 (99.28%)\n",
            "Top-3 accuracy: 0.9910 (99.10%)\n",
            "Top-5 accuracy: 0.9892 (98.92%)\n",
            "==================================================\n",
            "\n",
            "***Error analysis saved to: error_analysis.json***\n",
            "\n",
            "***Summary:\n",
            "   k=1: 4 errors out of 558 samples\n",
            "   k=3: 5 errors out of 558 samples\n",
            "   k=5: 6 errors out of 558 samples\n",
            "CPU times: user 1.42 s, sys: 15.5 ms, total: 1.44 s\n",
            "Wall time: 2.89 s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Evaluate accuracy for different k values\n",
        "print(\"Evaluating accuracy on test set...\")\n",
        "accuracy_results, error_results = evaluate_knn_accuracy(\n",
        "    X_test_emb,\n",
        "    y_test,\n",
        "    test_metadata,\n",
        "    index,\n",
        "    train_metadata,\n",
        "    k_values=[1, 3, 5]\n",
        ")\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ACCURACY RESULTS\")\n",
        "print(\"=\"*50)\n",
        "for k, accuracy in accuracy_results.items():\n",
        "    print(f\"Top-{k} accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Save error analysis to JSON file\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "error_analysis = {\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'model': MODEL_NAME,\n",
        "    'test_size': len(X_test_emb),\n",
        "    'accuracy_results': accuracy_results,\n",
        "    'errors_by_k': {}\n",
        "}\n",
        "\n",
        "for k, errors in error_results.items():\n",
        "    error_analysis['errors_by_k'][f'k_{k}'] = {\n",
        "        'total_errors': len(errors),\n",
        "        'error_rate': len(errors) / len(X_test_emb),\n",
        "        'errors': errors\n",
        "    }\n",
        "\n",
        "# Save to JSON file\n",
        "output_file = 'error_analysis.json'\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(error_analysis, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"\\n***Error analysis saved to: {output_file}***\")\n",
        "print()\n",
        "print(f\"***Summary:\")\n",
        "for k, errors in error_results.items():\n",
        "    print(f\"   k={k}: {len(errors)} errors out of {len(X_test_emb)} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6SsPqhb4foD"
      },
      "source": [
        "## Pipeline Classification for user input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pPLTYG8H4kWy"
      },
      "outputs": [],
      "source": [
        "def spam_classifier_pipeline(user_input, k=3):\n",
        "    \"\"\"\n",
        "    Complete pipeline for spam classification\n",
        "\n",
        "    Args:\n",
        "        user_input (str): Text to classify\n",
        "        k (int): Number of nearest neighbors to consider\n",
        "\n",
        "    Returns:\n",
        "        dict: Classification results with details\n",
        "    \"\"\"\n",
        "\n",
        "    print()\n",
        "    print(f\"***Classifying: '{user_input}'\")\n",
        "    print()\n",
        "    print(f\"***Using top-{k} nearest neighbors\")\n",
        "    print()\n",
        "\n",
        "    # Get prediction and neighbors\n",
        "    prediction, neighbors = classify_with_knn(\n",
        "        user_input, model, tokenizer, device, index, train_metadata, k=k\n",
        "    )\n",
        "\n",
        "    # Display results\n",
        "    print(f\"***Prediction: {prediction.upper()}\")\n",
        "    print()\n",
        "\n",
        "    print(\"***Top neighbors:\")\n",
        "    for i, neighbor in enumerate(neighbors, 1):\n",
        "        print(f\"{i}. Label: {neighbor['label']} | Score: {neighbor['score']:.4f}\")\n",
        "        print(f\"   Message: {neighbor['message']}\")\n",
        "        print()\n",
        "\n",
        "    # Count label distribution\n",
        "    labels = [n['label'] for n in neighbors]\n",
        "    label_counts = {label: labels.count(label) for label in set(labels)}\n",
        "\n",
        "    return {\n",
        "        'prediction': prediction,\n",
        "        'neighbors': neighbors,\n",
        "        'label_distribution': label_counts\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbWyfvp84nJb"
      },
      "source": [
        "## Test pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmjxbzNO4qHi",
        "outputId": "47e13d1c-ce4f-4f52-ced1-08dcd7c553a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing pipeline with different examples:\n",
            "\n",
            "\n",
            "***Example 1:\n",
            "\n",
            "***Classifying: 'I am actually thinking a way of doing something useful'\n",
            "\n",
            "***Using top-3 nearest neighbors\n",
            "\n",
            "***Prediction: HAM\n",
            "\n",
            "***Top neighbors:\n",
            "1. Label: ham | Score: 0.8378\n",
            "   Message: K, I'll work something out\n",
            "\n",
            "2. Label: ham | Score: 0.8376\n",
            "   Message: I have gone into get info bt dont know what to do\n",
            "\n",
            "3. Label: ham | Score: 0.8327\n",
            "   Message: Same. Wana plan a trip sometme then\n",
            "\n",
            "\n",
            "\n",
            "***Example 2:\n",
            "\n",
            "***Classifying: 'FREE!! Click here to win $1000 NOW! Limited time offer!'\n",
            "\n",
            "***Using top-3 nearest neighbors\n",
            "\n",
            "***Prediction: SPAM\n",
            "\n",
            "***Top neighbors:\n",
            "1. Label: spam | Score: 0.8572\n",
            "   Message: URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to ...\n",
            "\n",
            "2. Label: spam | Score: 0.8556\n",
            "   Message: Win a £1000 cash prize or a prize worth £5000\n",
            "\n",
            "3. Label: spam | Score: 0.8545\n",
            "   Message: For your chance to WIN a FREE Bluetooth Headset then simply reply back with \"ADP\"\n",
            "\n",
            "\n",
            "\n",
            "***Example 3:\n",
            "\n",
            "***Classifying: 'Hey, can you pick me up at 5pm today?'\n",
            "\n",
            "***Using top-3 nearest neighbors\n",
            "\n",
            "***Prediction: HAM\n",
            "\n",
            "***Top neighbors:\n",
            "1. Label: ham | Score: 0.8709\n",
            "   Message: Then ü come n pick me at 530 ar?\n",
            "\n",
            "2. Label: ham | Score: 0.8648\n",
            "   Message: Aiya we discuss later lar... Pick ü up at 4 is it?\n",
            "\n",
            "3. Label: ham | Score: 0.8628\n",
            "   Message: Are you free now?can i call now?\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test với các ví dụ khác nhau\n",
        "test_examples = [\n",
        "    \"I am actually thinking a way of doing something useful\",\n",
        "    \"FREE!! Click here to win $1000 NOW! Limited time offer!\",\n",
        "    \"Hey, can you pick me up at 5pm today?\",\n",
        "    # \"URGENT: Your account will be suspended unless you verify your details NOW\",\n",
        "    # \"Thanks for the meeting today, let's schedule the next one for next week\",\n",
        "    # \"Congratulations! You've won a prize! Call this number to claim it\"\n",
        "]\n",
        "\n",
        "print(\"Testing pipeline with different examples:\")\n",
        "print()\n",
        "\n",
        "for i, example in enumerate(test_examples, 1):\n",
        "    print(f\"\\n***Example {i}:\")\n",
        "    result = spam_classifier_pipeline(example, k=3)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mXO8PXg4znt",
        "outputId": "54f1e1d0-bf6f-4ce4-f152-7f6c67d9bbf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "***Interactive Testing\n",
            "\n",
            "***Testing with k=5\n",
            "\n",
            "***Classifying: 'Win a free iPhone! Click here now!'\n",
            "\n",
            "***Using top-5 nearest neighbors\n",
            "\n",
            "***Prediction: SPAM\n",
            "\n",
            "***Top neighbors:\n",
            "1. Label: spam | Score: 0.8663\n",
            "   Message: FREE entry into our £250 weekly competition just text the word WIN to 80086 NOW. 18 T&C www.txttowin...\n",
            "\n",
            "2. Label: spam | Score: 0.8591\n",
            "   Message: TheMob>Yo yo yo-Here comes a new selection of hot downloads for our members to get for FREE! Just cl...\n",
            "\n",
            "3. Label: spam | Score: 0.8580\n",
            "   Message: U have won a nokia 6230 plus a free digital camera. This is what u get when u win our FREE auction. ...\n",
            "\n",
            "4. Label: spam | Score: 0.8573\n",
            "   Message: Call FREEPHONE 0800 542 0578 now!\n",
            "\n",
            "5. Label: spam | Score: 0.8572\n",
            "   Message: important information 4 orange user . today is your lucky day!2find out why log onto http://www.uraw...\n",
            "\n",
            "***To test with different inputs:\n",
            "1. Change 'user_text' variable above\n",
            "2. Change 'k_value' for different number of neighbors\n",
            "3. Re-run this cell\n"
          ]
        }
      ],
      "source": [
        "# Interactive testing - user có thể thay đổi text và k value\n",
        "print(\"***Interactive Testing\")\n",
        "print()\n",
        "\n",
        "# Người dùng có thể thay đổi các giá trị này để test với các ví dụ khác nhau\n",
        "user_text = \"Win a free iPhone! Click here now!\"\n",
        "k_value = 5\n",
        "\n",
        "print(f\"***Testing with k={k_value}\")\n",
        "result = spam_classifier_pipeline(user_text, k=k_value)\n",
        "\n",
        "print(\"***To test with different inputs:\")\n",
        "print(\"1. Change 'user_text' variable above\")\n",
        "print(\"2. Change 'k_value' for different number of neighbors\")\n",
        "print(\"3. Re-run this cell\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
